Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 107, in <module>
    train_loaders, eval_loaders = get_img_dataloader(args)   #加载数据集
  File "H:\课题代码\DeepDG\datautil\getdataloader.py", line 19, in get_img_dataloader
    tedatalist.append(ImageDataset(args.dataset, args.task, args.data_dir,
TypeError: __init__() got an unexpected keyword argument 'test_envenvs'
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 107, in <module>
    train_loaders, eval_loaders = get_img_dataloader(args)   #加载数据集
  File "H:\课题代码\DeepDG\datautil\getdataloader.py", line 19, in get_img_dataloader
    tedatalist.append(ImageDataset(args.dataset, args.task, args.data_dir,
TypeError: __init__() got an unexpected keyword argument 'test_envenvs'
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 141, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 28, in update
    loss = F.cross_entropy(self.predict(all_x), all_y)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 38, in predict
    return self.network(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "H:\课题代码\DeepDG\network\img_network.py", line 52, in forward
    x = self.layer2(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\resnet.py", line 154, in forward
    out = self.conv3(out)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 4.00 GiB total capacity; 2.81 GiB already allocated; 0 bytes free; 2.84 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 138, in <module>
    if args.algorithm == 'VREx' and algorithm.update_count == args.anneal_iters:
KeyboardInterrupt
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "H:/课题代码/DeepDG/train.py", line 141, in <module>
    
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 28, in update
    loss = F.cross_entropy(self.predict(all_x), all_y)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 38, in predict
    return self.network(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "H:\课题代码\DeepDG\network\img_network.py", line 52, in forward
    x = self.layer2(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\resnet.py", line 154, in forward
    out = self.conv3(out)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 4.00 GiB total capacity; 2.81 GiB already allocated; 0 bytes free; 2.84 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "H:/课题代码/DeepDG/train.py", line 140, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 28, in update
    loss = F.cross_entropy(self.predict(all_x), all_y)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 38, in predict
    return self.network(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "H:\课题代码\DeepDG\network\img_network.py", line 52, in forward
    x = self.layer2(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\resnet.py", line 154, in forward
    out = self.conv3(out)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 4.00 GiB total capacity; 2.81 GiB already allocated; 0 bytes free; 2.84 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "H:/课题代码/DeepDG/train.py", line 125, in <module>
    algorithm.teanettrain(train_loaders, n_steps, opt1, sch1)
  File "H:\课题代码\DeepDG\alg\algs\DIFEX.py", line 45, in teanettrain
    all_p = self.teaNet(all_z)   #输入到教师网络中预测
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "H:\课题代码\DeepDG\network\img_network.py", line 52, in forward
    x = self.layer2(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\resnet.py", line 147, in forward
    out = self.bn1(out)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\batchnorm.py", line 168, in forward
    return F.batch_norm(
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\functional.py", line 2438, in batch_norm
    return torch.batch_norm(
RuntimeError: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 4.00 GiB total capacity; 2.80 GiB already allocated; 0 bytes free; 2.89 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 140, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 28, in update
    loss = F.cross_entropy(self.predict(all_x), all_y)
KeyboardInterrupt
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 137, in <module>
    if args.algorithm == 'VREx' and algorithm.update_count == args.anneal_iters:
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 116, in <module>
    train_loaders, eval_loaders = get_img_dataloader(args)   #加载数据集
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 116, in <module>
    train_loaders, eval_loaders = get_img_dataloader(args)   #加载数据集
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "H:/课题代码/DeepDG/train.py", line 119, in <module>
    eval_name_dict = train_valid_target_eval_names(args)
  File "H:\课题代码\DeepDG\utils\util.py", line 32, in train_valid_target_eval_names
    for i in range(args.domain_num):
AttributeError: 'Namespace' object has no attribute 'domain_num'
Traceback (most recent call last):
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "H:/课题代码/DeepDG/train.py", line 119, in <module>
    eval_name_dict = train_valid_target_eval_names(args)
  File "H:\课题代码\DeepDG\utils\util.py", line 32, in train_valid_target_eval_names
    for i in range(args.domain_num):
AttributeError: 'Namespace' object has no attribute 'domain_num'
Traceback (most recent call last):
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "H:/课题代码/DeepDG/train.py", line 119, in <module>
    eval_name_dict = train_valid_target_eval_names(args)
  File "H:\课题代码\DeepDG\utils\util.py", line 32, in train_valid_target_eval_names
    for i in range(args.domain_num):
AttributeError: 'Namespace' object has no attribute 'domain_num'
Traceback (most recent call last):
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "H:/课题代码/DeepDG/train.py", line 119, in <module>
    eval_name_dict = train_valid_target_eval_names(args)
  File "H:\课题代码\DeepDG\utils\util.py", line 32, in train_valid_target_eval_names
    for i in range(args.domain_num):
AttributeError: 'Namespace' object has no attribute 'domain_num'
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 119, in <module>
    eval_name_dict = train_valid_target_eval_names(args)
  File "H:\课题代码\DeepDG\utils\util.py", line 32, in train_valid_target_eval_names
    for i in range(args.domain_num):
AttributeError: 'Namespace' object has no attribute 'domain_num'
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 121, in <module>
    eval_name_dict = train_valid_target_eval_names(args)
KeyboardInterrupt
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 150, in <module>
    if args.algorithm == 'VREx' and algorithm.update_count == args.anneal_iters:
KeyboardInterrupt
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "H:/课题代码/DeepDG/train.py", line 153, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 28, in update
    loss = F.cross_entropy(self.predict(all_x), all_y)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 38, in predict
    return self.network(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "H:\课题代码\DeepDG\network\img_network.py", line 52, in forward
    x = self.layer2(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\resnet.py", line 154, in forward
    out = self.conv3(out)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: CUDA out of memory. Tried to allocate 98.00 MiB (GPU 0; 4.00 GiB total capacity; 2.81 GiB already allocated; 0 bytes free; 2.84 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 122, in <module>
    train_list.append(source2_train_data)
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 132, in <module>
    train_loaders = DataLoader(train_list, batch_size=16, shuffle=True)
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 136, in <module>
    algorithm_class = alg.get_algorithm_class(args.algorithm)
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 137, in <module>
    algorithm = algorithm_class(args).cuda()
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 20, in __init__
    args.num_classes, self.featurizer.in_features, args.classifier)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1207, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'CNNModel' object has no attribute 'in_features'
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 137, in <module>
    algorithm = algorithm_class(args).cuda()
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 20, in __init__
    args.num_classes, self.featurizer.in_features, args.classifier)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1207, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'CNNModel' object has no attribute 'in_features'
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 157, in <module>
    train_minibatches_iterator = zip(*train_loaders)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\utils\data\dataloader.py", line 681, in __next__
    data = self._next_data()
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\utils\data\dataloader.py", line 721, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in fetch
    return self.collate_fn(data)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\utils\data\_utils\collate.py", line 183, in default_collate
    raise TypeError(default_collate_err_msg_format.format(elem_type))
TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'torch.utils.data.dataset.Subset'>
Traceback (most recent call last):
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\utils\data\dataloader.py", line 681, in __next__
    data = self._next_data()
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\utils\data\dataloader.py", line 721, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in fetch
    return self.collate_fn(data)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\utils\data\_utils\collate.py", line 183, in default_collate
    raise TypeError(default_collate_err_msg_format.format(elem_type))
TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'torch.utils.data.dataset.Subset'>
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 133, in <module>
    eval_name_dict = {'train': [0, 1], 'valid': [2, 3], 'target': [4]}
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 133, in <module>
    eval_name_dict = {'train': [0, 1], 'valid': [2, 3], 'target': [4]}
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 167, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 26, in update
    all_x = torch.cat([data[0].cuda().float() for data in minibatches])
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 26, in <listcomp>
    all_x = torch.cat([data[0].cuda().float() for data in minibatches])
AttributeError: 'numpy.ndarray' object has no attribute 'cuda'
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 164, in <module>
    if args.algorithm == 'VREx' and algorithm.update_count == args.anneal_iters:
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 164, in <module>
    minibatches_device = minibatches_device.cuda()
AttributeError: 'list' object has no attribute 'cuda'
H:/课题代码/DeepDG/train.py:164: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\cb\pytorch_1000000000000\work\torch\csrc\utils\tensor_new.cpp:204.)
  minibatches_device = torch.tensor(minibatches_device).cuda()
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 164, in <module>
    minibatches_device = torch.tensor(minibatches_device).cuda()
ValueError: expected sequence of length 2 at dim 2 (got 1)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 164, in <module>
    minibatches_device = torch.tensor(minibatches_device).cuda()
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 164, in <module>
    minibatches_device = torch.from_numpy(minibatches_device).cuda()
TypeError: expected np.ndarray (got list)
H:/课题代码/DeepDG/train.py:164: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\cb\pytorch_1000000000000\work\torch\csrc\utils\tensor_new.cpp:204.)
  minibatches_device = torch.tensor(minibatches_device)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 164, in <module>
    minibatches_device = torch.tensor(minibatches_device)
ValueError: expected sequence of length 2 at dim 2 (got 1)
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
E:\Anaconda\envs\test-gpu\lib\site-packages\torchvision\models\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Traceback (most recent call last):
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "H:/课题代码/DeepDG/train.py", line 164, in <module>
    minibatches_device = torch.tensor(minibatches_device)
ValueError: only one element tensors can be converted to Python scalars
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 165, in <module>
    if args.algorithm == 'VREx' and algorithm.update_count == args.anneal_iters:
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "H:/课题代码/DeepDG/train.py", line 165, in <module>
    minibatches_device = [(torch.from_numpy(data)) for data in next(train_minibatches_iterator)]
  File "H:/课题代码/DeepDG/train.py", line 165, in <listcomp>
    minibatches_device = [(torch.from_numpy(data)) for data in next(train_minibatches_iterator)]
TypeError: expected np.ndarray (got tuple)
H:/课题代码/DeepDG/train.py:165: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\cb\pytorch_1000000000000\work\torch\csrc\utils\tensor_new.cpp:204.)
  minibatches_device = [(torch.tensor(data)) for data in next(train_minibatches_iterator)]
Traceback (most recent call last):
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "H:/课题代码/DeepDG/train.py", line 165, in <module>
    minibatches_device = [(torch.tensor(data)) for data in next(train_minibatches_iterator)]
  File "H:/课题代码/DeepDG/train.py", line 165, in <listcomp>
    minibatches_device = [(torch.tensor(data)) for data in next(train_minibatches_iterator)]
ValueError: expected sequence of length 2 at dim 1 (got 1)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 170, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 26, in update
    all_x = torch.cat([data[0].cuda().float() for data in minibatches])
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 26, in <listcomp>
    all_x = torch.cat([data[0].cuda().float() for data in minibatches])
AttributeError: 'numpy.ndarray' object has no attribute 'cuda'
Traceback (most recent call last):
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "H:/课题代码/DeepDG/train.py", line 170, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 26, in update
    all_x = torch.cat([data[0].cuda().float() for data in minibatches])
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 26, in <listcomp>
    all_x = torch.cat([data[0].cuda().float() for data in minibatches])
AttributeError: 'numpy.ndarray' object has no attribute 'cuda'
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 170, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 28, in update
    all_x = torch.cat([data[0].cuda().float() for data in minibatches])
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 135, in <module>
    eval_name_dict = {'train': [0, 1], 'valid': [2, 3], 'target': [4]}
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 160, in <module>
    best_valid_acc, target_acc = 0, 0
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 167, in <module>
    if args.algorithm == 'VREx' and algorithm.update_count == args.anneal_iters:
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 165, in <module>
    best_valid_acc, target_acc = 0, 0
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 164, in <module>
    best_valid_acc, target_acc = 0, 0
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "H:/课题代码/DeepDG/train.py", line 162, in <module>
    for batch1, batch2 in zip(*train1_loaders, *train2_loaders):
ValueError: too many values to unpack (expected 2)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 135, in <module>
    eval_loaders = DataLoader(test_list, batch_size=32, shuffle=True).dataset
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 135, in <module>
    eval_loaders = DataLoader(test_list, batch_size=32, shuffle=True).dataset
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\utils\data\dataloader.py", line 681, in __next__
    data = self._next_data()
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\utils\data\dataloader.py", line 721, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in fetch
    return self.collate_fn(data)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\utils\data\_utils\collate.py", line 183, in default_collate
    raise TypeError(default_collate_err_msg_format.format(elem_type))
TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'torch.utils.data.dataset.Subset'>
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 134, in <module>
    eval_loaders = DataLoader(test_list, batch_size=32, shuffle=True).dataset
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 134, in <module>
    eval_loaders = DataLoader(test_list, batch_size=32, shuffle=True).dataset
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 167, in <module>
    if args.algorithm == 'VREx' and algorithm.update_count == args.anneal_iters:
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 137, in <module>
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 138, in <module>
    eval_loaders = DataLoader(test_list, batch_size=32, shuffle=True).dataset
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 142, in <module>
    eval_loaders = DataLoader(test_list, batch_size=32, shuffle=True).dataset
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 142, in <module>
    eval_loaders = DataLoader(test_list, batch_size=32, shuffle=True).dataset
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 146, in <module>
    eval_loaders = DataLoader(test_list, batch_size=32, shuffle=True).dataset
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 178, in <module>
    if args.algorithm == 'VREx' and algorithm.update_count == args.anneal_iters:
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 30, in update
    loss = F.cross_entropy(self.predict(all_x), all_y)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 40, in predict
    return self.network(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "H:\课题代码\DeepDG\network\img_network.py", line 161, in forward
    x = x.expand(x.data.shape[0], 0, 4800)
RuntimeError: The expanded size of the tensor (0) must match the existing size (2) at non-singleton dimension 1.  Target sizes: [64, 0, 4800].  Tensor sizes: [64, 2, 4800]
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 30, in update
    loss = F.cross_entropy(self.predict(all_x), all_y)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 40, in predict
    return self.network(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "H:\课题代码\DeepDG\network\common_network.py", line 37, in forward
    x = self.fc(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x5400 and 300x31)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 30, in update
    loss = F.cross_entropy(self.predict(all_x), all_y)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 40, in predict
    return self.network(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "H:\课题代码\DeepDG\network\common_network.py", line 37, in forward
    x = self.fc(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x5400 and 300x10)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 150, in <module>
    algorithm = algorithm_class(args).cuda()
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 19, in __init__
    self.classifier = common_network.feat_classifier(
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 150, in <module>
    algorithm = algorithm_class(args).cuda()
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 19, in __init__
    self.classifier = common_network.feat_classifier(
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 30, in update
    loss = F.cross_entropy(self.predict(all_x), all_y)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 40, in predict
    return self.network(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "H:\课题代码\DeepDG\network\common_network.py", line 37, in forward
    x = self.fc(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x5400 and 300x10)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 30, in update
    loss = F.cross_entropy(self.predict(all_x), all_y)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 40, in predict
    return self.network(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "H:\课题代码\DeepDG\network\common_network.py", line 37, in forward
    x = self.fc(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x5400 and 300x10)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 30, in update
    loss = F.cross_entropy(self.predict(all_x), all_y)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 40, in predict
    return self.network(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "H:\课题代码\DeepDG\network\common_network.py", line 37, in forward
    x = self.fc(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x5400 and 300x10)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 30, in update
    loss = F.cross_entropy(self.predict(all_x), all_y)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\functional.py", line 3014, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 31, in update
    loss = F.cross_entropy(self.predict(all_x), all_y)
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 32, in update
    loss = F.cross_entropy(class_indices, all_y)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\functional.py", line 3014, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: "host_softmax" not implemented for 'Long'
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 32, in update
    loss = F.cross_entropy(class_indices, all_y)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\functional.py", line 3014, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 32, in update
    loss = F.cross_entropy(class_indices, all_y)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\functional.py", line 3014, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: "host_softmax" not implemented for 'Long'
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 31, in update
    class_indices = torch.argmax(one_hot_targets, dim=1)
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 32, in update
    loss = F.cross_entropy(class_indices, all_y)
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 32, in update
    loss = F.cross_entropy(class_indices, all_y)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\functional.py", line 3014, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: "host_softmax" not implemented for 'Long'
Traceback (most recent call last):
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 32, in update
    loss = F.cross_entropy(class_indices, all_y)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\functional.py", line 3014, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: "host_softmax" not implemented for 'Long'
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 32, in update
    loss = F.cross_entropy(class_indices, all_y)
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 33, in update
    loss = F.cross_entropy(class_indices, all_y)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\functional.py", line 3014, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
Traceback (most recent call last):
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 31, in update
    class_indices = torch.argmax(one_hot_targets, dim=2)
IndexError: Dimension out of range (expected to be in range of [-2, 1], but got 2)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 33, in update
    loss = F.cross_entropy(class_indices, all_y)
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 34, in update
    loss = F.cross_entropy(class_indices, all_y)
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 37, in update
    loss.backward()
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\autograd\__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
Traceback (most recent call last):
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 31, in update
    one_hot_targets = self.predict(all_x)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 44, in predict
    return self.network(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "H:\课题代码\DeepDG\network\img_network.py", line 162, in forward
    x = self.feature(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\conv.py", line 307, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\conv.py", line 303, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
RuntimeError: Input type (torch.cuda.LongTensor) and weight type (torch.cuda.FloatTensor) should be the same
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 34, in update
    loss = F.cross_entropy(class_indices, all_y)
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 34, in update
    loss = F.cross_entropy(class_indices, all_y)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\functional.py", line 3014, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected floating point type for target with class probabilities, got Long
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 34, in update
    loss = F.cross_entropy(class_indices, all_y)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\functional.py", line 3014, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected floating point type for target with class probabilities, got Long
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 34, in update
    loss = F.cross_entropy(class_indices, all_y)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\functional.py", line 3014, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: "host_softmax" not implemented for 'Long'
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 181, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 37, in update
    loss.backward()
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\autograd\__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
H:\课题代码\DeepDG\alg\algs\ERM.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(class_indices.float(), requires_grad=True)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 196, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "H:/课题代码/DeepDG/train.py", line 196, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "H:\课题代码\DeepDG\alg\modelopera.py", line 26, in accuracy
    x = data[0].cuda().float()
AttributeError: 'numpy.ndarray' object has no attribute 'cuda'
H:\课题代码\DeepDG\alg\algs\ERM.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(class_indices.float(), requires_grad=True)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 196, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "H:/课题代码/DeepDG/train.py", line 196, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "H:\课题代码\DeepDG\alg\modelopera.py", line 30, in accuracy
    p = network.predict(x)
  File "H:\课题代码\DeepDG\alg\algs\ERM.py", line 44, in predict
    return self.network(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "H:\课题代码\DeepDG\network\img_network.py", line 162, in forward
    x = self.feature(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\functional.py", line 1455, in relu
    result = torch.relu_(input)
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "H:/课题代码/DeepDG/train.py", line 150, in <module>
    algorithm = algorithm_class(args).cuda()
  File "H:\课题代码\DeepDG\alg\algs\DIFEX.py", line 19, in __init__
    self.featurizer.in_features, args.bottleneck, args.layer)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1207, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'CNNModel' object has no attribute 'in_features'
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 163, in <module>
    opt1 = get_optimizer(algorithm.teaNet, args, isteacher=True)
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "H:\课题代码\DeepDG\alg\algs\DIFEX.py", line 46, in teanettrain
    all_z = torch.angle(torch.fft.fftn(all_x, dim=(2, 3)))    #傅里叶变换
IndexError: Dimension out of range (expected to be in range of [-3, 2], but got 3)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "H:\课题代码\DeepDG\alg\algs\DIFEX.py", line 46, in teanettrain
    all_z = torch.angle(torch.fft.fftn(all_x, dim=(2, 3)))    #傅里叶变换
KeyboardInterrupt
Traceback (most recent call last):
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\pydevd.py", line 1483, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "E:\PyCharm\PyCharm 2021.2.2\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "H:/课题代码/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "H:\课题代码\DeepDG\alg\algs\DIFEX.py", line 46, in teanettrain
    all_z = torch.angle(torch.fft.fftn(all_x, dim=(2, 3)))    #傅里叶变换
IndexError: Dimension out of range (expected to be in range of [-3, 2], but got 3)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "H:\课题代码\DeepDG\alg\algs\DIFEX.py", line 46, in teanettrain
    all_z = torch.angle(torch.fft.fftn(all_x, dim=(2, 3)))    #傅里叶变换
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "H:\课题代码\DeepDG\alg\algs\DIFEX.py", line 47, in teanettrain
    all_y = torch.cat([data[1].cuda().long() for data in minibatches])  #合并输入标签
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "H:\课题代码\DeepDG\alg\algs\DIFEX.py", line 49, in teanettrain
    loss = F.cross_entropy(all_p, all_y, reduction='mean')  #使用预测结果 all_p 和真实标签 all_y 来计算交叉熵损失。
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\functional.py", line 3014, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "H:\课题代码\DeepDG\alg\algs\DIFEX.py", line 50, in teanettrain
    loss = F.cross_entropy(all_p, all_y, reduction='mean')  #使用预测结果 all_p 和真实标签 all_y 来计算交叉熵损失。
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "H:\课题代码\DeepDG\alg\algs\DIFEX.py", line 55, in teanettrain
    loss = F.cross_entropy(all_p, all_y, reduction='mean')  #使用预测结果 all_p 和真实标签 all_y 来计算交叉熵损失。
KeyboardInterrupt
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "H:\课题代码\DeepDG\alg\algs\DIFEX.py", line 55, in teanettrain
    loss = F.cross_entropy(all_p, all_y, reduction='mean')  #使用预测结果 all_p 和真实标签 all_y 来计算交叉熵损失。
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\functional.py", line 3014, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: Expected floating point type for target with class probabilities, got Long
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "H:\课题代码\DeepDG\alg\algs\DIFEX.py", line 57, in teanettrain
    loss.backward()
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\autograd\__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
H:\课题代码\DeepDG\alg\algs\DIFEX.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
Traceback (most recent call last):
  File "H:/课题代码/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "H:\课题代码\DeepDG\alg\algs\DIFEX.py", line 49, in teanettrain
    all_p = self.teaNet(all_z)   #输入到教师网络中预测
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "H:\课题代码\DeepDG\network\img_network.py", line 162, in forward
    x = self.feature(x)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\container.py", line 139, in forward
    input = module(input)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\conv.py", line 307, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "E:\Anaconda\envs\test-gpu\lib\site-packages\torch\nn\modules\conv.py", line 303, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 49, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/img_network.py", line 162, in forward
    x = self.feature(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 92, in forward
    return F.max_pool1d(input, self.kernel_size, self.stride,
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/_jit_internal.py", line 484, in fn
    return if_false(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 696, in _max_pool1d
    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 88, in update
    all_x1 = torch.angle(torch.fft.fftn(all_x, dim=(2, 3)))
IndexError: Dimension out of range (expected to be in range of [-3, 2], but got 3)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 92, in update
    loss1 = F.cross_entropy(self.classifier(all_z), all_y)   #绫绘澶
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 93, in update
    loss1 = F.cross_entropy(self.classifier(all_z), all_y)   #绫绘澶
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: "nll_loss_forward_reduce_cuda_kernel_2d_index" not implemented for 'Float'
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z = torch.tensor(all_z.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 95, in update
    loss1 = F.cross_entropy(self.classifier(all_z), all_y)   #绫绘澶
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 37, in forward
    x = self.fc(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x64 and 256x10)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z = torch.tensor(all_z.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 95, in update
    loss1 = F.cross_entropy(self.classifier(all_z), all_y)   #绫绘澶
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:52: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z = torch.tensor(all_z.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 95, in update
    loss1 = F.cross_entropy(self.classifier(all_z), all_y)   #绫绘澶
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 37, in forward
    x = self.fc(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (1x64 and 256x10)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z = torch.tensor(all_z.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 97, in update
    loss1 = F.cross_entropy(self.classifier(all_z), all_y)   #绫绘澶
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: size mismatch (got input: [10], target: [64])
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z = torch.tensor(all_z.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 98, in update
    loss1 = F.cross_entropy(self.classifier(all_z), all_y)   #绫绘澶
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: size mismatch (got input: [10], target: [64])
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z = torch.tensor(all_z.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 98, in update
    loss1 = F.cross_entropy(self.classifier(all_z), all_y)   #绫绘澶
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z = torch.tensor(all_z.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 99, in update
    loss1 = F.cross_entropy(self.classifier(all_z), all_y)   #绫绘澶
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 51, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 21, in forward
    return x
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z = torch.tensor(all_z.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 99, in update
    loss1 = F.cross_entropy(self.classifier(all_z), all_y)   #绫绘澶
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 95, in update
    all_z = self.classifier(all_z)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 37, in forward
    x = self.fc(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x256 and 64x10)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z = torch.tensor(all_z.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 99, in update
    loss1 = F.cross_entropy(self.classifier(all_z), all_y)   #绫绘澶
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z = torch.tensor(all_z.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 101, in update
    loss2 = F.mse_loss(all_z[:, :self.tfbd], tfea)*self.args.alpha  #甯瀛涔寸MSE澶
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z = torch.tensor(all_z.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 101, in update
    loss2 = F.mse_loss(all_z[:, :self.tfbd], tfea)*self.args.alpha  #甯瀛涔寸MSE澶
IndexError: too many indices for tensor of dimension 1
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z = torch.tensor(all_z.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:101: UserWarning: Using a target size (torch.Size([64, 128])) that is different to the input size (torch.Size([64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  loss2 = F.mse_loss(all_z[:self.tfbd, ], tfea)*self.args.alpha  #甯瀛涔寸MSE澶
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 101, in update
    loss2 = F.mse_loss(all_z[:self.tfbd, ], tfea)*self.args.alpha  #甯瀛涔寸MSE澶
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 3294, in mse_loss
    expanded_input, expanded_target = torch.broadcast_tensors(input, target)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/functional.py", line 74, in broadcast_tensors
    return _VF.broadcast_tensors(tensors)  # type: ignore[attr-defined]
RuntimeError: The size of tensor a (64) must match the size of tensor b (128) at non-singleton dimension 1
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(class_indices.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(class_indices.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 51, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 18, in forward
    x = self.bottleneck(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x100 and 5400x128)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 51, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 18, in forward
    x = self.bottleneck(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x100 and 5400x128)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 51, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 18, in forward
    x = self.bottleneck(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x100 and 5400x128)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z = torch.tensor(all_z.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 101, in update
    loss2 = F.mse_loss(all_z[:self.tfbd, ], tfea)*self.args.alpha  #甯瀛涔寸MSE澶
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z = torch.tensor(all_z.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 100, in update
    pp = all_z[:, :self.tfbd]
IndexError: too many indices for tensor of dimension 1
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 96, in update
    all_z = torch.argmax(all_z, dim=1)
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 95, in update
    all_z = self.classifier(all_z)
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z1 = torch.tensor(all_z1.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 103, in update
    if self.args.disttype == '2-norm':
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z1 = torch.tensor(all_z1.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:97: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z1 = torch.tensor(all_z1.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_y = torch.tensor(all_y, requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_y = torch.tensor(all_y, requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:99: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z1 = torch.tensor(all_z1.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 28, in accuracy
    x = torch.from_numpy(data[0]).cuda().float()
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:101: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z1 = torch.tensor(all_z1.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 30, in accuracy
    p = network.predict(x)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 142, in predict
    return self.classifier(self.bottleneck(self.featurizer(x)))
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/img_network.py", line 165, in forward
    x = self.feature(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 313, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 309, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 64, in teanettrain
    loss.backward()
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 31, in update
    one_hot_targets = self.predict(all_x)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 44, in predict
    return self.network(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 37, in forward
    x = self.fc(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x256 and 100x10)
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(class_indices.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(class_indices.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(class_indices.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 30, in accuracy
    p = network.predict(x)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 47, in predict
    return self.network(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/img_network.py", line 165, in forward
    x = self.feature(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 313, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 309, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(class_indices.float())
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 40, in update
    loss.backward()
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(class_indices.float())
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 41, in update
    loss.backward()
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(class_indices.float())
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 39, in update
    opt.zero_grad()
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(class_indices.float())
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 40, in update
    loss = loss_class(class_indices, all_y)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 2704, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: "nll_loss_forward_reduce_cuda_kernel_1d_index" not implemented for 'Float'
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(class_indices.float())
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 40, in update
    loss = loss_class(class_indices, all_y)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 34, in update
    one_hot_targets = self.predict(all_x)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 34, in update
    one_hot_targets = self.predict(all_x)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 51, in predict
    return self.network(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/img_network.py", line 165, in forward
    x = self.feature(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 313, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 309, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
RuntimeError: Input type (torch.cuda.IntTensor) and weight type (torch.cuda.FloatTensor) should be the same
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 36, in update
    class_indices = torch.tensor(class_indices.float())
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 40, in update
    loss = loss_class(class_indices, all_y)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 2704, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: "nll_loss_forward_reduce_cuda_kernel_1d" not implemented for 'Long'
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(class_indices.int())
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 40, in update
    loss = loss_class(class_indices, all_y)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 2704, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: "nll_loss_forward_reduce_cuda_kernel_1d" not implemented for 'Int'
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 36, in update
    class_indices = torch.tensor(class_indices.int32())
AttributeError: 'Tensor' object has no attribute 'int32'
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 40, in update
    loss = loss_class(one_hot_targets, all_y)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 2704, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: "nll_loss_forward_reduce_cuda_kernel_2d_index" not implemented for 'Int'
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 40, in update
    loss = loss_class(one_hot_targets, all_y)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 2704, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: "nll_loss_forward_reduce_cuda_kernel_2d_index" not implemented for 'Float'
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 40, in update
    loss = loss_class(one_hot_targets, all_y)
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 40, in update
    loss = loss_class(one_hot_targets, all_y)
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 40, in update
    loss = loss_class(one_hot_targets, all_y)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 2704, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: "nll_loss_forward_reduce_cuda_kernel_2d_index" not implemented for 'Float'
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 43, in update
    opt.zero_grad()
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 43, in update
    opt.zero_grad()
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 35, in accuracy
    correct += (p.argmax(1).eq(y).float()).sum().item()
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 43, in update
    opt.zero_grad()
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 184, in <module>
    if (epoch in [int(args.max_epoch*0.7), int(args.max_epoch*0.9)]) and (not args.schuse):
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 49, in update
    return {'class': loss.item()}
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 48, in update
    lossww = loss.item().float()
AttributeError: 'float' object has no attribute 'float'
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 30, in accuracy
    p = network.predict(x)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 52, in predict
    return self.network(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 216, in forward
    for module in self:
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 207, in __iter__
    @_copy_to_script_wrapper
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 44, in update
    loss.backward()
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 30, in accuracy
    p = network.predict(x)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 52, in predict
    return self.network(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/img_network.py", line 165, in forward
    x = self.feature(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 313, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 309, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 30, in accuracy
    p = network.predict(x)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 52, in predict
    return self.network(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/img_network.py", line 165, in forward
    x = self.feature(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 55, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 18, in forward
    x = self.bottleneck(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x5400 and 256x128)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 55, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 18, in forward
    x = self.bottleneck(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x5400 and 256x128)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 55, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 47, in forward
    x = self.class_classifier(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x128 and 5400x300)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 64, in teanettrain
    loss.backward()
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:58: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_p = torch.tensor(all_p.float(), requires_grad=True)
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z1 = torch.tensor(all_z1.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 30, in accuracy
    p = network.predict(x)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 143, in predict
    return self.classifier(self.bottleneck(self.featurizer(x)))
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/img_network.py", line 165, in forward
    x = self.feature(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 313, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 309, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
KeyboardInterrupt
/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py:105: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  all_z1 = torch.tensor(all_z1.float(), requires_grad=True)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 30, in accuracy
    p = network.predict(x)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 146, in predict
    return self.classifier(self.bottleneck(self.featurizer(x)))
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/img_network.py", line 165, in forward
    x = self.feature(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 313, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 309, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 55, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/img_network.py", line 165, in forward
    x = self.feature(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/pooling.py", line 92, in forward
    return F.max_pool1d(input, self.kernel_size, self.stride,
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/_jit_internal.py", line 484, in fn
    return if_false(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 696, in _max_pool1d
    return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 67, in teanettrain
    loss.backward()
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 100, in update
    tfea = self.teab(self.teaf(all_x1)).detach()
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 18, in forward
    x = self.bottleneck(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x10 and 5400x128)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 34, in update
    one_hot_targets = self.predict(all_x)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 52, in predict
    return self.network(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 48, in forward
    x = self.fc(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x10 and 256x10)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 55, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 28, in forward
    x = self.feat_bottleneck(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x10 and 5400x300)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 55, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 55, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 28, in forward
    x = self.feat_bottleneck(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x10 and 5400x300)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 55, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 28, in forward
    x = self.feat_bottleneck(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x10 and 5400x300)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 55, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 28, in forward
    x = self.feat_bottleneck(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x10 and 5400x300)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 55, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 28, in forward
    x = self.feat_bottleneck(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x10 and 5400x300)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 55, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 28, in forward
    x = self.class_classifier(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x10 and 5400x300)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 55, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 28, in forward
    x = self.class_classifier(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: running_mean should contain 128 elements not 100
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 56, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 28, in forward
    x = self.class_classifier(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: running_mean should contain 50 elements not 100
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 56, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 28, in forward
    x = self.class_classifier(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: running_mean should contain 50 elements not 100
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 56, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 28, in forward
    x = self.class_classifier(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: running_mean should contain 50 elements not 100
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 56, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 30, in forward
    x = self.bn(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'feat_bottleneck' object has no attribute 'bn'
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 56, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 58, in forward
    x = self.fc(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'feat_classifier' object has no attribute 'fc'
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 56, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 58, in forward
    x = self.fc(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1614, in __getattr__
    raise AttributeError("'{}' object has no attribute '{}'".format(
AttributeError: 'feat_classifier' object has no attribute 'fc'
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 166, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 61, in teanettrain
    all_y = all_y.squeeze()
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 103, in update
    all_z = self.bottleneck(self.featurizer(all_x))          #瑰--缃缁
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 28, in forward
    x = self.class_classifier(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 2450, in batch_norm
    return torch.batch_norm(
RuntimeError: running_mean should contain 256 elements not 100
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 147, in update
    return {'class': loss1.item(), 'dist': (loss2).item(), 'exp': (loss3).item(), 'align': loss4.item(), 'total': loss.item()}
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 30, in accuracy
    p = network.predict(x)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 150, in predict
    return self.classifier(self.bottleneck(self.featurizer(x)))
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/img_network.py", line 172, in forward
    x = self.feature(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py", line 171, in forward
    return F.batch_norm(
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 2451, in batch_norm
    input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/backends/__init__.py", line 32, in __get__
    return self.getter()
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 34, in update
    one_hot_targets = self.predict(all_x)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 52, in predict
    return self.network(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 57, in forward
    x = self.class_classifier(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x5400 and 256x10)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 34, in update
    one_hot_targets = self.predict(all_x)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 52, in predict
    return self.network(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 84, in forward
    x = self.class_classifier(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x5400 and 100x10)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 182, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 34, in update
    one_hot_targets = self.predict(all_x)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 52, in predict
    return self.network(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 84, in forward
    x = self.class_classifier(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x5400 and 100x10)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 30, in accuracy
    p = network.predict(x)
  File "/home/liuchang/DG/DeepDG/alg/algs/ERM.py", line 52, in predict
    return self.network(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 84, in forward
    x = self.class_classifier(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 32, in accuracy
    if p.size(1) == 1:
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 197, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
TypeError: 'DataLoader' object is not subscriptable
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
NameError: name 'eval_loaders' is not defined
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 28, in accuracy
    x = torch.from_numpy(data[0]).cuda().float()
TypeError: expected np.ndarray (got Tensor)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, test_list[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, test_list[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 30, in accuracy
    if p.size(1) == 1:
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 44, in accuracy
    x = torch.cat([data[0].cuda().float() for data in loader])
RuntimeError: Tensors must have same number of dimensions: got 2 and 1
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, test_list[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, test_list[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 49, in accuracy
    if p.size(1) == 1:
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, test_list[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, test_list[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 53, in accuracy
    total += len(x)
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, test_list[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, test_list[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 55, in accuracy
    network.train()
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, test_list[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, test_list[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 56, in accuracy
    network.train()
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, test_list[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, test_list[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 50, in accuracy
    if p.size(1) == 1:
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 186, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 52, in teanettrain
    all_x = torch.cat([data[0].cuda().float() for data in minibatches])  #骞惰ユ版
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 186, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 54, in teanettrain
    all_z = torch.angle(torch.fft.fftn(all_x, dim=(1, 2)))    #跺
IndexError: Dimension out of range (expected to be in range of [-2, 1], but got 2)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 186, in <module>
    algorithm.teanettrain(minibatches_device, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 56, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/img_network.py", line 171, in forward
    x = x.expand(x.data.shape[0], 2, 4800)
RuntimeError: The expanded size of the tensor (2) must match the existing size (4) at non-singleton dimension 1.  Target sizes: [4, 2, 4800].  Tensor sizes: [4, 4800]
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 128, in <module>
    device1, device2 = [], []
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 169, in <module>
    algorithm_class = alg.get_algorithm_class(args.algorithm)
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 167, in <module>
    train_loaders, eval_loaders = get_img_dataloader1(args)   #杞芥版
  File "/home/liuchang/DG/DeepDG/datautil/getdataloader.py", line 97, in get_img_dataloader1
    return train_loaders, eval_loaders
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 186, in <module>
    algorithm.teanettrain(train_loaders, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 56, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 46, in accuracy
    x = loader[0].cuda().float()
TypeError: 'DataLoader' object is not subscriptable
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 103, in update
    all_z = self.bottleneck(self.featurizer(all_x))          #瑰--缃缁
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/img_network.py", line 172, in forward
    x = self.feature(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 313, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py", line 309, in _conv_forward
    return F.conv1d(input, weight, bias, self.stride,
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 37, in accuracy
    network.train()
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 186, in <module>
    algorithm.teanettrain(train_loaders, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 45, in teanettrain
    for epoch in range(epochs):
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 186, in <module>
    algorithm.teanettrain(train_loaders, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 48, in teanettrain
    all_x = torch.cat([data[0].cuda().float() for data in minibatches])  #骞惰ユ版
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 186, in <module>
    algorithm.teanettrain(train_loaders, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 50, in teanettrain
    all_z = torch.angle(torch.fft.fftn(all_x, dim=(1, 2)))    #跺
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 186, in <module>
    algorithm.teanettrain(train_loaders, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 62, in teanettrain
    loss = F.cross_entropy(all_p, all_y, reduction='mean')  #浣跨ㄩ娴缁 all_p 瀹绛 all_y ヨ＄浜ゅ垫澶便
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 30, in accuracy
    if p.size(1) == 1:
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 30, in accuracy
    correct1 = (p.argmax(1).eq(y).float()).sum().item()
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 30, in accuracy
    correct1 = (p.argmax(1).eq(y).float()).sum().item()
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 31, in accuracy
    if p.size(1) == 1:
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 167, in <module>
    train_loaders, eval_loaders = get_img_dataloader1(args)   #杞芥版
  File "/home/liuchang/DG/DeepDG/datautil/getdataloader.py", line 77, in get_img_dataloader1
    target = SignalDataset1('XY_10_400_-5dB.mat')
  File "/home/liuchang/DG/DeepDG/datautil/mydata_read.py", line 128, in __init__
    self.X, self.Y = load_h5(data_folder)   # (3392, 8192, 1)
  File "/home/liuchang/DG/DeepDG/datautil/mydata_read.py", line 16, in load_h5
    with h5py.File(h5_path, 'r') as hf:
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/h5py/_hl/files.py", line 567, in __init__
    fid = make_fid(name, mode, userblock_size, fapl, fcpl, swmr=swmr)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/h5py/_hl/files.py", line 231, in make_fid
    fid = h5f.open(name, flags, fapl=fapl)
  File "h5py/_objects.pyx", line 54, in h5py._objects.with_phil.wrapper
  File "h5py/_objects.pyx", line 55, in h5py._objects.with_phil.wrapper
  File "h5py/h5f.pyx", line 106, in h5py.h5f.open
FileNotFoundError: [Errno 2] Unable to open file (unable to open file: name = 'XY_10_400_-5dB.mat', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/Mixup.py", line 17, in update
    for (xi, yi, di), (xj, yj, dj) in random_pairs_of_minibatches(self.args, minibatches):
  File "/home/liuchang/DG/DeepDG/datautil/util.py", line 41, in random_pairs_of_minibatches
    minibatches[tdi][0][txi], dim=0), minibatches[tdi][1][txi], minibatches[tdi][2][txi]
IndexError: list index out of range
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/CORAL.py", line 37, in update
    objective += F.cross_entropy(classifs[i], targets[i])
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/MMD.py", line 49, in update
    objective += F.cross_entropy(classifs[i], targets[i])
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/MLDG.py", line 38, in update
    inner_obj = F.cross_entropy(inner_net(xi), yi)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/GroupDRO.py", line 25, in update
    losses[m] = F.cross_entropy(self.predict(x), y)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/RSC.py", line 45, in update
    mask = torch.logical_or(mask_f, mask_b).float()
RuntimeError: The size of tensor a (64) must match the size of tensor b (640) at non-singleton dimension 0
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 110, in <module>
    loss_list = alg_loss_dict(args)
  File "/home/liuchang/DG/DeepDG/utils/util.py", line 58, in alg_loss_dict
    return loss_dict[args.algorithm]
KeyError: 'ANDmask'
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ANDMask.py", line 26, in update
    env_loss = F.cross_entropy(logits, y)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/VREx.py", line 32, in update
    nll = F.cross_entropy(logits, data[1].cuda().long())
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/CORAL.py", line 37, in update
    objective += F.cross_entropy(classifs[i], targets[i])
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/CORAL.py", line 37, in update
    objective += F.cross_entropy(classifs[i], targets[i])
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/CORAL.py", line 41, in update
    objective += loss_class(classifs[i], targets[i])
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/loss.py", line 216, in forward
    return F.nll_loss(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 2704, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/CORAL.py", line 42, in update
    for j in range(i + 1, nmb):
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/CORAL.py", line 55, in update
    penalty = penalty.item()
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 217, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 34, in accuracy
    correct += (p.argmax(1).eq(y).float()).sum().item()
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/MMD.py", line 67, in update
    penalty = penalty.item()
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/MLDG.py", line 38, in update
    inner_obj = F.cross_entropy(inner_net(xi), yi)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/MLDG.py", line 38, in update
    inner_obj = F.cross_entropy(inner_net(xi), yi)
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/MLDG.py", line 44, in update
    inner_opt.zero_grad()
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/MLDG.py", line 57, in update
    loss_inner_j = F.cross_entropy(inner_net(xj), yj)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/MLDG.py", line 62, in update
    objective += (self.args.mldg_beta * loss_inner_j).item()
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/MLDG.py", line 45, in update
    inner_opt.zero_grad()
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/GroupDRO.py", line 37, in update
    loss.backward()
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/ANDMask.py", line 25, in update
    x, y = data[0].cuda().float(), data[1].cuda().long()
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/Mixup.py", line 17, in update
    for (xi, yi, di), (xj, yj, dj) in random_pairs_of_minibatches(self.args, minibatches):
  File "/home/liuchang/DG/DeepDG/datautil/util.py", line 41, in random_pairs_of_minibatches
    minibatches[tdi][0][txi], dim=0), minibatches[tdi][1][txi], minibatches[tdi][2][txi]
IndexError: list index out of range
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/Mixup.py", line 17, in update
    for (xi, yi, di), (xj, yj, dj) in random_pairs_of_minibatches(self.args, minibatches):
  File "/home/liuchang/DG/DeepDG/datautil/util.py", line 39, in random_pairs_of_minibatches
    if j == 0:
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/Mixup.py", line 17, in update
    for (xi, yi, di), (xj, yj, dj) in random_pairs_of_minibatches(self.args, minibatches):
  File "/home/liuchang/DG/DeepDG/datautil/util.py", line 41, in random_pairs_of_minibatches
    minibatches[tdi][0][txi], dim=0), minibatches[tdi][1][txi], minibatches[tdi][2][txi]
IndexError: list index out of range
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/Mixup.py", line 17, in update
    for (xi, yi, di), (xj, yj, dj) in random_pairs_of_minibatches(self.args, minibatches):
  File "/home/liuchang/DG/DeepDG/datautil/util.py", line 41, in random_pairs_of_minibatches
    minibatches[tdi][0][txi], dim=0), minibatches[tdi][1][txi], minibatches[tdi][2][txi]
IndexError: list index out of range
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/Mixup.py", line 17, in update
    for (xi, yi, di), (xj, yj, dj) in random_pairs_of_minibatches(self.args, minibatches):
  File "/home/liuchang/DG/DeepDG/datautil/util.py", line 39, in random_pairs_of_minibatches
    if j == 0:
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 167, in <module>
    train_loaders, eval_loaders = get_img_dataloader1(args)   #杞芥版
  File "/home/liuchang/DG/DeepDG/datautil/getdataloader.py", line 82, in get_img_dataloader1
    train_loaders = [InfiniteDataLoader(
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 169, in <module>
    algorithm_class = alg.get_algorithm_class(args.algorithm)
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 192, in <module>
    best_valid_acc, target_acc = 0, 0
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 199, in <module>
    if args.algorithm == 'VREx' and algorithm.update_count == args.anneal_iters:
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 200, in <module>
    if args.algorithm == 'VREx' and algorithm.update_count == args.anneal_iters:
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd.py", line 1500, in _exec
    pydev_imports.execfile(file, globals, locals)  # execute the script
  File "/home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/_pydev_imps/_pydev_execfile.py", line 18, in execfile
    exec(compile(contents+"\n", file, 'exec'), glob, loc)
  File "/home/liuchang/DG/DeepDG/train.py", line 204, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/Mixup.py", line 17, in update
    for (xi, yi, di), (xj, yj, dj) in random_pairs_of_minibatches(self.args, minibatches):
  File "/home/liuchang/DG/DeepDG/datautil/util.py", line 41, in random_pairs_of_minibatches
    minibatches[tdi][0][txi], dim=0), minibatches[tdi][1][txi], minibatches[tdi][2][txi]
IndexError: list index out of range
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 202, in <module>
    if args.algorithm == 'VREx' and algorithm.update_count == args.anneal_iters:
KeyboardInterrupt
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 205, in <module>
    if args.algorithm == 'VREx' and algorithm.update_count == args.anneal_iters:
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 208, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/Mixup.py", line 17, in update
    for (xi, yi, di), (xj, yj, dj) in random_pairs_of_minibatches(self.args, minibatches):
  File "/home/liuchang/DG/DeepDG/datautil/util.py", line 46, in random_pairs_of_minibatches
    (yi, minibatches[tdi][1][txi])), torch.hstack((di, minibatches[tdi][2][txi]))
TypeError: expected Tensor as element 0 in argument 0, but got numpy.ndarray
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 206, in <module>
    if args.algorithm == 'VREx' and algorithm.update_count == args.anneal_iters:
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 224, in <module>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/train.py", line 224, in <listcomp>
    acc_record[item] = np.mean(np.array([modelopera.accuracy(algorithm, eval_loaders[i]) for i in eval_name_dict[item]]))
  File "/home/liuchang/DG/DeepDG/alg/modelopera.py", line 25, in accuracy
    for data in loader:
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1328, in _next_data
    idx, data = self._get_data()
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1294, in _get_data
    success, data = self._try_get_data()
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1132, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 209, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/RSC.py", line 45, in update
    mask = torch.logical_or(mask_f, mask_b).float()
RuntimeError: The size of tensor a (64) must match the size of tensor b (640) at non-singleton dimension 0
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
Error loading: /home/gpu/涓杞/pycharm-professional-2023.2.1/pycharm-2023.2.1/plugins/python/helpers/pydev/pydevd_attach_to_process/attach_linux_amd64.so
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 209, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/RSC.py", line 45, in update
    mask = torch.logical_or(mask_f, mask_b).float()
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 209, in <module>
    step_vals = algorithm.update(minibatches_device, opt, sch)
  File "/home/liuchang/DG/DeepDG/alg/algs/RSC.py", line 52, in update
    loss = F.cross_entropy(all_p_muted_again, all_y)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py", line 3029, in cross_entropy
    return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)
RuntimeError: 0D or 1D target tensor expected, multi-target not supported
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 186, in <module>
    algorithm.teanettrain(train_loaders, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 52, in teanettrain
    all_p = self.teaNet(all_z)   #杈ュ版甯缃缁涓棰娴
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/DG/DeepDG/network/common_network.py", line 28, in forward
    x = self.class_classifier(x)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py", line 217, in forward
    input = module(input)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x2400 and 5400x300)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/DG/DeepDG/alg/algs/ERM.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  class_indices = torch.tensor(one_hot_targets.float())
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 167, in <module>
    train_loaders, eval_loaders = get_img_dataloader1(args)   #杞芥版
  File "/home/liuchang/DG/DeepDG/datautil/getdataloader.py", line 84, in get_img_dataloader1
    train_loaders = [InfiniteDataLoader(
  File "/home/liuchang/DG/DeepDG/datautil/getdataloader.py", line 84, in <listcomp>
    train_loaders = [InfiniteDataLoader(
  File "/home/liuchang/DG/DeepDG/datautil/mydataloader.py", line 38, in __init__
    self._infinite_iterator = iter(torch.utils.data.DataLoader(
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 441, in __iter__
    return self._get_iterator()
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 388, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1084, in __init__
    self._reset(loader, first_iter=True)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1117, in _reset
    self._try_put_index()
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1351, in _try_put_index
    index = self._next_index()
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 623, in _next_index
    return next(self._sampler_iter)  # may raise StopIteration
  File "/home/liuchang/DG/DeepDG/datautil/mydataloader.py", line 14, in __iter__
    for batch in self.sampler:
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/sampler.py", line 247, in __iter__
    batch = [next(sampler_iter) for _ in range(self.batch_size)]
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/sampler.py", line 247, in <listcomp>
    batch = [next(sampler_iter) for _ in range(self.batch_size)]
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/sampler.py", line 122, in __iter__
    generator.manual_seed(seed)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 168, in <module>
    train_loaders, eval_loaders = get_img_dataloader1(args)   #杞芥版
  File "/home/liuchang/DG/DeepDG/datautil/getdataloader.py", line 84, in get_img_dataloader1
    train_loaders = [InfiniteDataLoader(
  File "/home/liuchang/DG/DeepDG/datautil/getdataloader.py", line 84, in <listcomp>
    train_loaders = [InfiniteDataLoader(
  File "/home/liuchang/DG/DeepDG/datautil/mydataloader.py", line 38, in __init__
    self._infinite_iterator = iter(torch.utils.data.DataLoader(
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 441, in __iter__
    return self._get_iterator()
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 388, in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1084, in __init__
    self._reset(loader, first_iter=True)
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1117, in _reset
    self._try_put_index()
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1351, in _try_put_index
    index = self._next_index()
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 623, in _next_index
    return next(self._sampler_iter)  # may raise StopIteration
  File "/home/liuchang/DG/DeepDG/datautil/mydataloader.py", line 14, in __iter__
    for batch in self.sampler:
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/sampler.py", line 247, in __iter__
    batch = [next(sampler_iter) for _ in range(self.batch_size)]
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/sampler.py", line 247, in <listcomp>
    batch = [next(sampler_iter) for _ in range(self.batch_size)]
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/sampler.py", line 129, in __iter__
    yield from torch.randint(high=n, size=(self.num_samples % 32,), dtype=torch.int64, generator=generator).tolist()
KeyboardInterrupt
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 203, in <module>
    len_batch2 = len(minibatches_device[1][1])
IndexError: list index out of range
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 168, in <module>
    train_loaders, eval_loaders = get_img_dataloader1(args)   #杞芥版
  File "/home/liuchang/DG/DeepDG/datautil/getdataloader.py", line 74, in get_img_dataloader1
    source2_train_data, source2_eval_data = torch.utils.data.random_split(source2,
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/dataset.py", line 353, in random_split
    raise ValueError("Sum of input lengths does not equal the length of the input dataset!")
ValueError: Sum of input lengths does not equal the length of the input dataset!
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 168, in <module>
    train_loaders, eval_loaders = get_img_dataloader1(args)   #杞芥版
  File "/home/liuchang/DG/DeepDG/datautil/getdataloader.py", line 74, in get_img_dataloader1
    source2_train_data, source2_eval_data = torch.utils.data.random_split(source2,
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/utils/data/dataset.py", line 353, in random_split
    raise ValueError("Sum of input lengths does not equal the length of the input dataset!")
ValueError: Sum of input lengths does not equal the length of the input dataset!
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
Traceback (most recent call last):
  File "/home/liuchang/DG/DeepDG/train.py", line 187, in <module>
    algorithm.teanettrain(train_loaders, n_steps, opt1, sch1)
  File "/home/liuchang/DG/DeepDG/alg/algs/DIFEX.py", line 64, in teanettrain
    loss.backward()
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA error: device-side assert triggered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/functional.py:1331: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).
  warnings.warn(warn_msg)
/home/liuchang/.conda/envs/Lizhuo3.9/lib/python3.9/site-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
